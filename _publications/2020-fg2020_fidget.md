---
title: "Automatic detection of self-adaptors for psychological distress"
collection: publications
permalink: /publication/16/11/2020-fg2020_fidget
excerpt: 'Psychological distress is a significant and growing issue in society. Automatic detection, assessment, and analysis of such distress is an active area of research. Compared to modalities such as face, head, and vocal, research investigating the use of the body modality for these tasks is relatively sparse. This is, in part, due to the lack of available datasets and difficulty in automatically extracting useful body features. Recent advances in pose estimation and deep learning have enabled new approaches to this modality and domain. We propose a novel method to automatically detect self-adaptors and fidgeting, a subset of self-adaptors that has been shown to be correlated with psychological distress. We also propose a multi-modal approach that combines different feature representations using Multi-modal Deep Denoising Auto-Encoders and Improved Fisher Vector encoding. We also demonstrate that our proposed model, combining audio-visual features with automatically detected fidgeting behavioral cues, can successfully predict distress levels in a dataset labeled with self-reported anxiety and depression levels. To enable this research we introduce a new dataset containing full body videos for short interviews and self-reported distress labels.'
date: 16/11/2020
venue: '2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/9320202'
citation: 'W. Lin, I. Orton, M. Liu and M. Mahmoud, &quot;Automatic Detection of Self-Adaptors for Psychological Distress,&quot; 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020), 2020, pp. 371-378, doi: 10.1109/FG47880.2020.00032.'
---

<a href='https://ieeexplore.ieee.org/abstract/document/9320202'>Download paper here</a>

Psychological distress is a significant and growing issue in society. Automatic detection, assessment, and analysis of such distress is an active area of research. Compared to modalities such as face, head, and vocal, research investigating the use of the body modality for these tasks is relatively sparse. This is, in part, due to the lack of available datasets and difficulty in automatically extracting useful body features. Recent advances in pose estimation and deep learning have enabled new approaches to this modality and domain. We propose a novel method to automatically detect self-adaptors and fidgeting, a subset of self-adaptors that has been shown to be correlated with psychological distress. We also propose a multi-modal approach that combines different feature representations using Multi-modal Deep Denoising Auto-Encoders and Improved Fisher Vector encoding. We also demonstrate that our proposed model, combining audio-visual features with automatically detected fidgeting behavioral cues, can successfully predict distress levels in a dataset labeled with self-reported anxiety and depression levels. To enable this research we introduce a new dataset containing full body videos for short interviews and self-reported distress labels.

Recommended citation: W. Lin, I. Orton, M. Liu and M. Mahmoud, "Automatic Detection of Self-Adaptors for Psychological Distress," 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020), 2020, pp. 371-378, doi: 10.1109/FG47880.2020.00032.